[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Practical Technicalities",
    "section": "",
    "text": "Warning\n\n\n\nThis chapter is currently under active development. Use its content as it is helpful, but please moderate your expectations. If you’re interested in helping out with its development, head over to the repo\n\n\nThis ‘book’ comprises a set of recommendations for the Canada Learning Code (CLC) evaluation team, aimed at helping them improve their data analysis and reporting process. The recommendations are based on the results of a review of the CLC evaluation team’s current process. The review of the CLC evaluation team’s current process was conducted by the author, in collaboration with the CLC evaluation team. The primary concerns of the recommendations are analysis methods and data management processes. A secondary concern is more forward looking, dealing with potential additions or modifications to CLC’s data collection strategy.\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "02-01_cwss-score.html",
    "href": "02-01_cwss-score.html",
    "title": "1  Calculating CWSS Scores",
    "section": "",
    "text": "In this brief primer on calculating CWSS scores, I’ll explain the mechanics of the calculation, then walk through an example by simulating some data and calculating CWSS scores for it."
  },
  {
    "objectID": "02-01_cwss-score.html#a-brief-overview-of-notation",
    "href": "02-01_cwss-score.html#a-brief-overview-of-notation",
    "title": "1  Calculating CWSS Scores",
    "section": "1.1 a brief overview of notation",
    "text": "1.1 a brief overview of notation\n\n\\(A\\) and \\(B\\) are each statements which could be true or false. We don’t know either way.\n\n\\(P(A)\\) is the probability of \\(A\\) being true, and \\(P(B)\\) is the probability of \\(B\\) being true.\n\\(P( \\neg A)\\) is the probability of \\(A\\) being false. It is always equal to \\(1-P(A)\\). This is also called the ‘inverse probability’ of \\(A\\).\n\\(P(A \\cup B)\\) is the probability of either \\(A\\) or \\(B\\) being true.\n\\(P(A \\cap B)\\) is the probability of both \\(A\\) and \\(B\\) being true."
  },
  {
    "objectID": "02-01_cwss-score.html#supporting-calculations",
    "href": "02-01_cwss-score.html#supporting-calculations",
    "title": "1  Calculating CWSS Scores",
    "section": "1.2 supporting calculations",
    "text": "1.2 supporting calculations\nIf \\(A\\) and \\(B\\) are independent, which is to say that knowing whether \\(A\\) is true or false doesn’t tell us anything about whether \\(B\\) is true or false, then the probability of both \\(A\\) and \\(B\\) being true \\(P(A \\cap B)\\) is the simple product of the probabilities \\(P(A) \\cdot P(B)\\). The probability of \\(A\\) or \\(B\\) being true is typically given as \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\), where you add up the probabilities of \\(A\\) and \\(B\\), and then subtract the probability of both being true to avoid double counting it. However, since we need to perform this calculation for more than two statements, and this formula doesn’t generalize especially naturally to more than two statements, we’ll do a bit of double negation to get the equivalent but more general formula \\(P(A \\cup B) = P(\\neg (\\neg A \\cap \\neg B)) = 1 - P(\\neg A \\cap \\neg B) = 1 - (1 - P(A)) * (1 - P(B))\\). This is a bit less intuitive as a formula, but it makes sense if you think about it as ‘the probability of either \\(A\\) or \\(B\\) bieng true is the same as the probability of neither \\(A\\) nor \\(B\\) being false’. If we had a third statement \\(C\\), we could add it to the formula as \\(P(A \\cup B \\cup C) = 1 - (1 - P(A)) * (1 - P(B)) * (1 - P(C))\\), and revise our natural language statement to be ‘the probability that any of \\(A\\), \\(B\\), or \\(C\\) is true is the same as the probability that none of \\(A\\), \\(B\\), or \\(C\\) is false’."
  },
  {
    "objectID": "02-01_cwss-score.html#cwss-in-the-abstract",
    "href": "02-01_cwss-score.html#cwss-in-the-abstract",
    "title": "1  Calculating CWSS Scores",
    "section": "1.3 cwss in the abstract",
    "text": "1.3 cwss in the abstract\nTo apply our supporting calculations to the CWSS score, we just need to replace the placeholder statements \\(A\\), \\(B\\), \\(C\\), and so on with the actual statements we’re interested in, like ‘learner is a woman or beyond the binary’ or ‘learner is Indigenous’. The current inputs to the CWSS score are estimates of the percentage of the participants for which each statement is true. We can use these percentages as probabilities directly, since they’re our best guess of the probability of each statement being true. For example (and for our purposes), “10% of learners are Indigenous” is the same as “the probability that a learner is Indigenous is 0.1” or \\(P(Indigenous) = 0.1\\). Equivalently, “80% of learners are women or beyond the binary” is the same as \\(P(Woman\\ or\\ beyond) = 0.8\\). If we were only striving to serve those two communities, we would calculate the CWSS score as \\(CWSS = P(Indigenous \\cup Woman\\ or\\ beyond) = 1 - (1 - P(Indigenous)) * (1 - P(Woman\\ or\\ beyond)) = 1 - (1 - 0.1) * (1 - 0.8) = 0.82\\). In reality, the CWSS score generated by this process is just an estimate of the true proportion of learners who belong to one or more of the target communities. Even if our assumption of independence holds, there will remain some error."
  },
  {
    "objectID": "02-01_cwss-score.html#an-example",
    "href": "02-01_cwss-score.html#an-example",
    "title": "1  Calculating CWSS Scores",
    "section": "1.4 an example",
    "text": "1.4 an example\n\n\n\n\n\n\nNote\n\n\n\nThroughout this example, I’m going to work in R because that’s what I’m familiar with. If you’re not comfortable with it, that’s all good, the important point is the math, not the code.\n\n\nThe R packages in the ‘tidyverse’ have grown to become the standard toolkit for data analysis in R. The dplyr package provides a critical set of data manipulation functions that make it easy to work with data in a way that’s easy to read and understand.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(ggdist)\n\nSome fake data about fake people. You won’t need to do this step, since you already have real data. This is just to illustrate the process and its accuracy.\n\n# sim_learners produces a tibble (a data frame) with n rows, each representing a learner.\n# Each column is a community we strive to serve\n# Each cell is TRUE if the learner belongs to that community, or FALSE if not\n# It also includes a column cwss_actual, which is true if the learner belongs to any of the communities\nsim_learners <- function(n) {\n    res <-\n        tibble::tibble(\n            women_and_beyond = sample(c(TRUE, FALSE), n, replace = TRUE, prob = c(0.5, 0.5)),\n            low_income = sample(c(TRUE, FALSE), n, replace = TRUE, prob = c(0.3, 0.7)),\n            newcomer = sample(c(TRUE, FALSE), n, replace = TRUE, prob = c(0.1, 0.9)),\n            physical_disability = sample(c(TRUE, FALSE), n, replace = TRUE, prob = c(0.05, 0.95))\n        ) |>\n        mutate(\n            cwss_actual = women_and_beyond | low_income | newcomer | physical_disability\n        )\n\n    res\n}\n# always set the random seed when you doing simulations\nset.seed(1234)\n\nlearners <- sim_learners(5000)\n\nreadr::write_rds(learners, \"data/learners.rds\")\n\nknitr::kable(head(learners))\n\n\n\n\n\n\n\n\n\n\n\nwomen_and_beyond\nlow_income\nnewcomer\nphysical_disability\ncwss_actual\n\n\n\n\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nTRUE\nFALSE\nFALSE\nFALSE\nTRUE\n\n\nTRUE\nTRUE\nFALSE\nFALSE\nTRUE\n\n\nTRUE\nFALSE\nTRUE\nFALSE\nTRUE\n\n\nTRUE\nFALSE\nFALSE\nFALSE\nTRUE\n\n\nTRUE\nTRUE\nFALSE\nFALSE\nTRUE\n\n\n\n\n\nNow that we have the data, we can calculate the membership probabilities for each community, then calculate the CWSS score and compare it to the CWSS actual value.\n\ncalculate_cwss <- function(d) {\n    d |>\n        summarize(across(everything(), mean)) |>\n        mutate(\n            cwss_score = 1 - (\n                (1 - women_and_beyond) *\n                    (1 - low_income) *\n                    (1 - newcomer) *\n                    (1 - physical_disability)\n            ),\n            cwss_error = cwss_score - cwss_actual\n        )\n}\n\ncwss_summary <- calculate_cwss(learners)\n\nreadr::write_rds(cwss_summary, \"data/cwss_summary.rds\")\n\nknitr::kable(cwss_summary)\n\n\n\n\n\n\n\n\n\n\n\n\n\nwomen_and_beyond\nlow_income\nnewcomer\nphysical_disability\ncwss_actual\ncwss_score\ncwss_error\n\n\n\n\n0.5014\n0.2968\n0.1002\n0.0468\n0.7018\n0.6992808\n-0.0025192\n\n\n\n\n\nWe can see that, with 5000 learners, the CWSS score is, in this case, accurate to a single percentage point. While this level of accuracy depends on the structural truth of the independence assumption (which we enforced in our simulation), it should indicate that this approach yields a more accurate and interpretable result than the current method."
  },
  {
    "objectID": "02-02_response-rates.html",
    "href": "02-02_response-rates.html",
    "title": "2  Understanding Response Rates",
    "section": "",
    "text": "In this section, we’ll tackle the challenge of outlining and explaining a methodology that makes the most out of survey data with low response rates without creating misleading or inaccurate results. Our discussion begins with a brief overview of the relationship between sample size and estimate accuracy, and then moves on to a discussion of the possible approaches to working with small samples and their relative merits and drawbacks."
  },
  {
    "objectID": "02-02_response-rates.html#sampling-error",
    "href": "02-02_response-rates.html#sampling-error",
    "title": "2  Understanding Response Rates",
    "section": "2.1 sampling error",
    "text": "2.1 sampling error\nTo illustrate the relationship bewteen sample size and sampling error, we’ll return to the simulated learners from the previous section.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(ggdist)\n\ncalculate_cwss <- function(d) {\n    d |>\n        summarize(across(everything(), mean)) |>\n        mutate(\n            cwss_score = 1 - (\n                (1 - women_and_beyond) *\n                    (1 - low_income) *\n                    (1 - newcomer) *\n                    (1 - physical_disability)\n            ),\n            cwss_error = cwss_score - cwss_actual\n        )\n}\n\nlearners <- readr::read_rds(\"data/learners.rds\")\ncwss_summary <- readr::read_rds(\"data/cwss_summary.rds\")\n\nStats courses on the subject will often begin with abstract examples, like drawing marbles from a bag, or flipping coins, but I’ve never found those particularly helpful, especially when we have a more concrete example available. Below, for a range of sample sizes between 5 and 2500, we draw and summarize 200 samples of that size from the simulated learners. For each sample of size \\(n\\) (which we can think of as a set of \\(n\\) survey responses), we calculate the representation of each relevant group in the sample, and compare that to the ‘true’ representation of that group in the population.\n\nsim_sample <- function(n, k) {\n    seq_len(k) |>\n        map(\n            ~ learners |>\n                sample_n(n, replace = FALSE) |>\n                calculate_cwss() |>\n                mutate(run = .x)\n        ) |>\n        bind_rows()\n}\n\ncwss_long <- cwss_summary |>\n    tidyr::pivot_longer(\n        everything(),\n        names_to = \"var\",\n        values_to = \"val\"\n    )\n\ncwss_validation <- cwss_long$val |>\n    purrr::set_names(cwss_long$var)\n\nsamples <-\n    tibble::tibble(\n        size = c(5, 10, 50, 100, 500, 1000, 2500),\n        samples = map(size, sim_sample, k = 200)\n    ) |>\n    unnest(samples)\n\n\nsample_errors <- samples |>\n    pivot_longer(\n        c(-run, -size),\n        names_to = \"var\",\n        values_to = \"estimate\"\n    ) |>\n    mutate(\n        var = forcats::fct_inorder(var),\n        population_value = cwss_validation[var],\n        empirical_error = estimate - population_value,\n        standard_error = (1 - estimate) * estimate / sqrt(size),\n    ) |>\n    group_by(size) |>\n    mutate(\n        mean_absolute_deviation = mean(abs(empirical_error)),\n        mean_se = mean(standard_error)\n    ) |>\n    ungroup() |>\n    mutate(size = factor(size))\n\n\n\nsample_errors |>\n    filter(!var %in% c(\"cwss_actual\", \"cwss_error\"), !(size == \"5\" & var == \"physical_disability\")) |>\n    ggplot(aes(x = size, y = empirical_error, fill = mean_absolute_deviation)) +\n    facet_grid(cols = vars(var)) +\n    ggdist::stat_slab(expand = T, trim = FALSE, height = 3, normalize = \"groups\", orientation = \"vertical\") +\n    bptheme::theme_blueprint() +\n    bpscales::scale_fill_blueprint(\n        type = \"multi\",\n        option = \"fsc\",\n        limits = c(0, .15),\n        breaks = c(0, .05, .1, .15),\n        guide = guide_colourbar(barwidth = 25, title.vjust = 1)\n    ) +\n    scale_y_continuous(limits = c(-1, 1), breaks = c(-1, -.5, -.25, -.1, -.05, 0, .05, .1, .25, .5, 1))\n\n\n\n\n(sampling-error?) shows the distribution of errors (the difference between the sample’s proportion and the population’s) for each sample size, and for each population group, including the calculated cwss_score. Distributions more tightly clustered around zero indicate less error, and thus more accurate estimates of representation in the population. The ‘slabs’ representing the distributions of errors are coloured to indicate the average absolute error for that sample size and population group. The average absolute error is the average of the absolute value of the error, and is a measure of the average distance between the sample’s estimate and the population’s true value.\nThe most prominent and obvious conclusion to draw is intuitive and unsurprising: larger samples yield more accurate estimates of population values. However, there are a few other important and interesting things to note:\n\nSmall samples are not entirely uninformative. Even samples of size 5, which are the smallest we consider here, provide some information about the population, which we can see by the fact that their average absolute error is less than .15, which is much smaller than the average absolute error we would expect if we guessed randomly (which would be .5).\nCompared to the individual characteristics, the cwss_score is much more stable across sample sizes. This is because the cwss_score is a composite of all the individual characteristics, and thus is less sensitive to the random variation in the sample.\nThe absolute size of the sample (e.g. 5, 10, 50) is much more important to the accuracy of the estimates it produces than is the relative size of the sample (e.g. .1%, .2%, 1%). This is why classical formulations of the margin of error (which we’ll get to later) depend only on the size of the sample, and not on the size of the population.\n\n\nsample_errors |>\n    filter(!var %in% c(\"cwss_actual\", \"cwss_error\"), !(size == \"5\" & var == \"physical_disability\")) |>\n    ggplot(aes(x = size, y = empirical_error)) +\n    facet_grid(cols = vars(var)) +\n    ggdist::stat_pointinterval() +\n    bptheme::theme_blueprint() +\n    scale_y_continuous(limits = c(-1, 1), breaks = c(-1, -.5, -.25, -.1, -.05, 0, .05, .1, .25, .5, 1))\n\n\n\n\n\n2.1.1 the margin of error\nOne of the most familiar situations in which we encounter sampling error is in the reporting of public opinion polls. In this context, the margin of error is a measure of the uncertainty in the estimate of the proportion of the population that holds a particular opinion. The margin of error is calculated using the sample size and the proportion of the sample that holds the opinion in question. It is calculated as the product of the standard error and a constant, which is determined by the desired level of confidence.\nFor a proportion (like our estimates of the representation of different groups in the population), the standard error is calculated as \\(\\sqrt{\\frac{p(1-p)}{n}}\\), where \\(p\\) is the proportion of the sample that holds the opinion in question, and \\(n\\) is the sample size. The constant is determined by the desired level of confidence, and is calculated as \\(z \\times \\sqrt{\\frac{p(1-p)}{n}}\\), where \\(z\\) is the z-score associated with the desired level of confidence. For the standard 95% level of confidence, \\(z\\) is 1.96. The relationship between \\(z\\) and the desired level of confidence is always the same.\n\nmoe <- expand_grid(\n    size = c(5, 10, 50, 100, 500, 1000, 2500),\n    p = c(.1, .5)\n)\n\nposition_nudgedodge <- function(nudge_x = 0, nudge_y = 0, width = 0.75) {\n    ggproto(NULL, PositionNudgeDodge, nudge_x = nudge_x, nudge_y = nudge_y, width = width)\n}\n\nPositionNudgeDodge <- ggproto(\"PositionNudgeDodge\", PositionDodge,\n    nudge_x = 0, nudge_y = 0, width = .75,\n    setup_params = function(self, data) {\n        l <- ggproto_parent(PositionDodge, self)$setup_params(data)\n        append(l, list(x = self$nudge_x, y = self$nudge_y))\n    },\n    compute_layer = function(self, data, params, layout) {\n        d <- ggproto_parent(PositionNudge, self)$compute_layer(data, params, layout)\n        d <- ggproto_parent(PositionDodge, self)$compute_layer(d, params, layout)\n        d\n    }\n)\n\nmoe |>\n    mutate(\n        se = sqrt(p * (1 - p) / size),\n        moe = 1.96 * se\n    ) |>\n    ggplot(aes(y = factor(size))) +\n    ggdist::stat_halfeye(\n        aes(\n            xdist = distributional::dist_normal(mean = p, sd = se)\n        ),\n        position = position_dodge(width = .3)\n    ) +\n    geom_text(\n        aes(x = p, group = p, label = glue::glue(\"{round(100 * p)}% +/- {round(moe * 100, 1)}\")),\n        position = position_nudgedodge(nudge_y = -.1, width = .3)\n    ) +\n    scale_x_continuous(breaks = c(0, .1, .5, 1)) +\n    labs(x = \"proportion\", y = \"sample size\") +\n    bptheme::theme_blueprint()\n\n\n\n\n(margin-of-error?) shows the margin of error for different sample sizes at 95% confidence for both 10% and 50% representation in the sample. Directionally, the margin of error agrees with the results of our survey simulations presented in (sampling-error?), but the formula produces somewhat more conservative (larger) estimates of the error.\n\n\n\n\n\n\nHow much error is too much error?\n\n\n\nThe answer to this question is a matter of judgement, and depends on the details of how CLC’s reporting will be used, interrogated, and judged both internally by program managers, and externally by funders and other stakeholders. Both (sampling-error?) and (margin-of-error?) demonstrate that samples of size 5 or 10 risk producing wildly incorrect (and therefore probably unacceptable) estimates, but that samples of size 100 or greater are quite likely to produce estimates within .1 (ten percentage points) of the true value.\nPublic opinion polls typically design their sampling and data collection strategies to produce estimates with a maximum margin of error (where the sample value is 50%) of no more than 3 or 4 percentage points, which requires a sample size of roughly 1000. CLC’s need for accuracy is probably not as great as that of a public opinion poll, but it may still be useful to set a benchmark in terms of the maximum acceptable margin of error."
  },
  {
    "objectID": "02-02_response-rates.html#borrowing-information-from-previous-months",
    "href": "02-02_response-rates.html#borrowing-information-from-previous-months",
    "title": "2  Understanding Response Rates",
    "section": "2.2 borrowing information from previous months",
    "text": "2.2 borrowing information from previous months\nCLC’s evaluation team has discussed their struggles with low response rates in the context of individual surveys administered within a given reporting period. However, CLC has the advantage of being able to combine results from multiple reporting periods to increase the sample size available for analysis. The current practice of discarding estimates from small samples and replacing them with the last available estimate from a larger sample prefigures this approach, but we can do better by using all the available data to produce a more accurate and current estimate.\n\n2.2.1 a simple moving average\nThe simplest way to combine estimates from multiple reporting periods is to pool responses from some number of previous reporting periods, and then calculate the proportion of each group in the pooled sample. To illustrate the benefits of this approach, we’ll arbitrarily divide our simulated population of learners into 12 reporting periods, draw ‘batches’ of small samples from each, calculate moving averages with different sizes of window, and then observe the error. For the sake of simplicity, we’ll focus on estimating the representation of women_and_beyond learners in the population, but the approach and the results are applicable to any other group.\nTo begin, I’ll divide our simulated learners into 12 ‘monthly’ reporting periods by adding a column to the data frame that indicates which reporting period each learner belongs to. The term period refers to some unit of time, which could be a month, a quarter, or a year, depending on the reporting cycle. I’ll keep the numeric period value, but label each period with a month name for the sake of concreteness and clarity.\n\nperiod_data <- learners |>\n    mutate(period = row_number() %% 12 + 1) |>\n    arrange(period) |>\n    mutate(\n        month = forcats::fct_inorder(month.abb[period]),\n        quarter = forcats::fct_inorder(glue::glue(\"Q{(period - 1) %/% 3 + 1}\"))\n    )\n\nperiod_summary <- period_data |>\n    group_by(quarter, month, period) |>\n    summarize(\n        N = n(),\n        n_women_and_beyond = sum(women_and_beyond),\n        p_women_and_beyond = mean(women_and_beyond)\n    ) |>\n    ungroup()\n\n`summarise()` has grouped output by 'quarter', 'month'. You can override using\nthe `.groups` argument.\n\nperiod_summary |>\n    ggplot(aes(month, p_women_and_beyond, group = 1)) +\n    geom_hline(yintercept = cwss_validation[\"women_and_beyond\"], linetype = \"dashed\") +\n    geom_path() +\n    annotate(\"text\", x = \"May\", y = .51, label = \"overall average\", hjust = 0) +\n    geom_point(aes(fill = quarter), size = 4, shape = 21) +\n    scale_y_continuous(limits = c(.25, .75)) +\n    bptheme::theme_blueprint()\n\n\n\n\n(data-moving-average?) shows the proportion of women_and_beyond learners in each reporting period, along with the overall average for the population. Since the division of the population into reporting periods is arbitrary, the proportion of women_and_beyond learners in each period varies somewhat between periods, but cleaves fairly closely to the overall average.\n\n\n2.2.2 calculation\nBefore we simulate a bunch of rounds of survey responses, I’ll calculate the population’s moving average, just to demonstrate the process.\n\nlibrary(RcppRoll)\nlibrary(ggformula)\n\nLoading required package: ggstance\n\n\n\nAttaching package: 'ggstance'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    geom_errorbarh, GeomErrorbarh\n\n\nLoading required package: scales\n\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nLoading required package: ggridges\n\n\n\nAttaching package: 'ggridges'\n\n\nThe following objects are masked from 'package:ggdist':\n\n    scale_point_color_continuous, scale_point_color_discrete,\n    scale_point_colour_continuous, scale_point_colour_discrete,\n    scale_point_fill_continuous, scale_point_fill_discrete,\n    scale_point_size_continuous\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nmoving_average_proportion <- function(N, n, window) {\n    roll_sum(n, window, fill = NA, align = \"right\") / roll_sum(N, window, fill = NA, align = \"right\")\n}\n\ncalc_example <- period_summary |>\n    mutate(\n        three_month_p = moving_average_proportion(N, n_women_and_beyond, 3)\n    )\n\n\ncalc_example |>\n    ggplot(aes(period, p_women_and_beyond)) +\n    geom_point(aes(fill = quarter), size = 4, shape = 21) +\n    geom_line(aes(x, y), data = function(d) data.frame(spline(d$period, d$three_month_p, n = 100))) +\n    geom_point(aes(y = three_month_p)) +\n    scale_y_continuous(limits = c(.25, .75)) +\n    scale_x_continuous(breaks = 1:12, labels = function(x) month.abb[x]) +\n    bptheme::theme_blueprint()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n(moving-average-example?) shows the moving average for the proportion of women_and_beyond learners in the population, calculated using a window of three months. Using the full set of monthly data, we can see that the three month moving average is smoother than the monthly data, and that it hews yet closer to the overall average across all reporting periods. This will remain true for subsequent calculations using simulated survey responses.\n\n\n2.2.3 survey simulation\n\nsim_monthly_women_and_beyond <- function(\n    d, # data frame of learners with period information\n    n, # number of survey responses to simulate\n    k # number of samples to generate for each reporting period\n    ) {\n    g <- d |> group_by(month, period)\n    seq_len(k) |>\n        map(function(i) {\n            g |>\n                sample_n(n, replace = FALSE) |>\n                summarize(N = n, n = sum(women_and_beyond), .groups = \"drop\") |>\n                mutate(iter = i)\n        }) |>\n        bind_rows() |>\n        ungroup()\n}\n\nmoving_average_samples <- sim_monthly_women_and_beyond(period_data, 15, 200) |>\n    group_by(iter) |>\n    mutate(\n        ma_1 = n / N,\n        ma_2 = moving_average_proportion(N, n, 2),\n        ma_3 = moving_average_proportion(N, n, 3),\n        ma_4 = moving_average_proportion(N, n, 4),\n        ma_5 = moving_average_proportion(N, n, 5),\n        ma_6 = moving_average_proportion(N, n, 6)\n    ) |>\n    pivot_longer(\n        matches(\"ma_\"),\n        names_pattern = \"ma_(\\\\d+)\",\n        names_to = \"window\",\n        values_to = \"p_moving_average\"\n    ) |>\n    filter(!is.na(p_moving_average))\n\nmoving_average_samples |>\n    ggplot(aes(window, p_moving_average)) +\n    stat_slab(aes(fill = window), expand = T, trim = FALSE, height = 3, normalize = \"groups\", orientation = \"vertical\") +\n    geom_hline(data = calc_example, aes(yintercept = p_women_and_beyond), linetype = \"dashed\") +\n    facet_grid(cols = vars(month), scales = \"free_x\", space = \"free_x\") +\n    bptheme::theme_blueprint() +\n    bpscales::scale_fill_blueprint(discrete = TRUE, type = \"multi\", option = \"fsc\") +\n    labs(fill = \"Number of months of data included in estimate\") +\n    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .1))\n\nWarning: Removed 38 rows containing missing values (`geom_slabinterval()`).\n\n\nWarning: Removed 32 rows containing missing values (`geom_slabinterval()`).\n\n\nWarning: Removed 43 rows containing missing values (`geom_slabinterval()`).\n\n\nWarning: Removed 31 rows containing missing values (`geom_slabinterval()`).\n\n\nWarning: Removed 26 rows containing missing values (`geom_slabinterval()`).\n\n\n\n\n\n(survey-data?) shows the distributions of estimates of the proportion of women_and_beyond learners in the population, calculated for each reporting period using different window sizes. The furthest left distribution in each panel shows the distribution of estimates calculated using only the data from that reporting period, and the distributions to the right show the distributions of estimates calculated using the data from that reporting period and the previous 1, 2, 3, 4, or 5 reporting periods. Because our simulated dataset only includes 12 months of data, the number of months of data available in January is limited to 1, the number in Februrary to 2, and so on.\nThe figure clearly shows that, as the window size (and therefore the sample size) increases, the distributions of estimates become more tightly clustered. However, it is also important to recognize that the center of their distribution shifts as well. This is because the population proportion of women_and_beyond learners varies somewhat between reporting periods, and so the estimates calculated using data from different reporting periods will vary as well. The trade-off this represents is quite common to statistical analysis: by using a moving average to reduce the error in our estimates, we bias those estimates towards the average of the population over the period of time covered by the moving average.\nUsing a moving average to borrow sample size from previous reporting periods is suitable for estimating the representation of population characteristics that CLC expects to be relatively stable over time (like gender). However, this approach should be used with caution where representation is expected to change dramatically between periods, especially if / when CLC is attempting to measure the impact of specific interventions.\n\n\n2.2.4 more complex moving averages\nThe moving average approach outlined above is simple and easy to implement, but it has a few drawbacks, which can be addressed by modifying its implementation.\n\nWeights can be applied to the data from each reporting period to place more emphasis on more recent data. This modification mitigates the bias towards the average of the population over the period of time covered by the moving average.\nThe window size can be adjusted to include just enough months of data to achieve an acceptable error. This modification also mitigates the bias toward the window average, but at the cost of a more complex implementation."
  },
  {
    "objectID": "02-02_response-rates.html#borrowing-information-from-other-sources",
    "href": "02-02_response-rates.html#borrowing-information-from-other-sources",
    "title": "2  Understanding Response Rates",
    "section": "2.3 borrowing information from other sources",
    "text": "2.3 borrowing information from other sources\nAs CLC has already recognized, information about the representation of different groups in the local population to which its learners belong is avilable from other sources, including the census and other population surveys. Rather than replacing estimates from small sample sizes entirely, it is possible, as we have seen, to instead augment those estimates with information from other sources. Above, we combined estimates from multiple reporting periods to increase the sample size available for analysis. Here, I’ll discuss two approaches to augmenting estimates from small samples with information from public data sources.\n\n\n\n\n\n\nGround rules for reporting estimates augmented with external data\n\n\n\nWhen reporting estimates like the ones generated by these methods, it is important to be honest and transparent about their construction. Where possible, stick to the following rules:\n\nPlainly describe the data and methods used to generate the estimates, preferably with direct links to the data\nAcknowledge the assumptions that underlie the methods\nJustify the assumptions in terms of their relevance to the population of interest\nAddress the risk of statistical bias introduced by the external data source alongside your interpretation and analysis\n\nAdherence to these guidelines will help to ensure that the estimates are not misinterpreted or misused, and will safeguard CLC’s reputation for rigorous and transparent evaluation.\n\n\n\n2.3.1 a simple weighted average\nThe simplest way to augment estimates from small samples with information from other sources is to calculate a weighted average of the estimate from the small sample and the estimate from the other source. The basic formula for a weighted average is \\(\\frac{\\sum_{i=1}^n w_i x_i}{\\sum_{i=1}^n w_i}\\), where \\(x_i\\) is the value of the \\(i\\) th observation, and \\(w_i\\) is the weight assigned to that observation. In the context of estimating the representation of a group in the population, the value of \\(x_i\\) is the estimate of the proportion of the group in the sample, and the value of \\(w_i\\) is the weight assigned to that estimate.\nIn the simplest example, where CLC is combining a single estimate from a small sample with a single estimate from a public data source, CLC has one choice to make: what weights to use, or how much to ‘trust’ each estimate. This choice boils down to a judgement call about how much information the public data source provides about the population of learners. In other words, the more that CLC expects the population of learners to resemble the population represented in the public data source, the more weight CLC should assign to the estimate from the public data source.\nIf we fix the weight for the estimate from the survey data at \\(n\\), where \\(n\\) is the number of responses to the survey, we can understand the weight applied to the public data as the number of learners we want the public data to ‘count’ for. For example, if we have 5 survey responses, and we want the public data to count for 10 learners, we would assign a weight of 5 to the survey data, and a weight of 10 to the public data. Of course, this would be equivalent to assigning a weight of 1 to the survey data, and a weight of 2 to the public data, but it is conceptually easier to think about the public data as ‘counting’ for a certain number of learners.\nImagining the weight as a number of learners, it is intuitive that the weight assigned to the public data should not exceed the number of non-responding learners in the sample. If we have 5 survey responses, and 3 non-responding learners, we can’t assign a weight of 10 to the public data, because that would imply that we have 13 learners in the sample, which we don’t. The weight must also be greater than or equal to 0, but within this range, the choice of which weight to assign the public data should be based on CLC’s conceptual analysis of the relationship between the population of learners and the population represented in the public data.\n\n\n\n\n\n\nA straightforward option\n\n\n\nThe challenge we’re attempting to address is having insufficient sample size to produce accurate estimates of the representation of different groups in the learner population. The option that addresses this challenge most directly is to establish a desired margin of error, calculate the required sample size \\(S\\), and then use the public data to ‘top up’ the sample size to \\(S\\). Plausible values for \\(S\\) range from 100 to 1000, depending on the desired level of precision.\nThe approach described above is not – strictly speaking – statistically rigorous, because it does not produce a reliable measure of uncertainty. As such, it’s not an approach that has received any attention in the statistical literature. It could be readily characterized as within the much underdeveloped field of ‘domain knowledge imputation’, but it is not a method that has been studied or validated, nor one for which there are established best practices.\nThe established best practice is to increase the sample size until the desired margin of error is achieved, and then to report the margin of error along with the estimate. However, this approach is not feasible for CLC, because the sample size is not strictly under CLC’s control.\n\n\nCLC’s current approach replaces unrealiable estimates with either the last available reliable estimate, or with a population estimate. The approach described here is much the same, but it works to augment rather than replace the unreliable estimate.\n\n\n2.3.2 a bayesian regression model\nA more statistically rigorous approach to augmenting estimates from small samples with information from other sources is to use a bayesian regression model with ‘informative priors’ based on the public data. The estimates produced by this approach will be very similar to those produced by the weighted average, but the model will produce measures of uncertainty that can be used to assess and report the reliability of the estimates.\n\n\n2.3.3 relevant public data sources\n\n2021 Census Profiles: includes usable population values for low income, rural, newcomer 2, indigenous, and racialized individuals at the FSA level. Sex representation is also available, but wouldn’t be useful for MLEs marketed specifically toward women and beyond (like ladies learning code, girls learning code).\n2017 Canadian Survey on Disability: includes usable population values for disability by age group and province.\nMonthly Ontario Public School Demographics: includes newcomer and low income representation among student bodies by school and school board, along with latitude and longitude for each school."
  }
]